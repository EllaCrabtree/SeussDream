{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers\n",
      "  Cloning https://github.com/huggingface/diffusers to /private/var/folders/4x/rm59z8nd499bqflq1y8ncqyr0000gq/T/pip-req-build-_lrmjwkv\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /private/var/folders/4x/rm59z8nd499bqflq1y8ncqyr0000gq/T/pip-req-build-_lrmjwkv\n",
      "  Resolved https://github.com/huggingface/diffusers to commit 7457aa67cb5c75132c38507080697b7cc7c4d9e6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (6.0.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (0.19.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (1.24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (2022.10.31)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (2.28.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from diffusers==0.24.0.dev0) (9.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/gianyrox1/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.19.4->diffusers==0.24.0.dev0) (23.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from importlib-metadata->diffusers==0.24.0.dev0) (3.12.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->diffusers==0.24.0.dev0) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->diffusers==0.24.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->diffusers==0.24.0.dev0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->diffusers==0.24.0.dev0) (2022.12.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'diffusers/examples/dreambooth/requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+https://github.com/huggingface/diffusers\n",
    "%pip install -U -r diffusers/examples/dreambooth/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /Users/gianyrox1/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't need to run if config exists\n",
    "\n",
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b69b512f51549a095c2f9d6606d8063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"/Users/gianyrox1/Library/Mobile Documents/com~apple~CloudDocs/GDD School/Stevens'24/Semester 7/CS 583 Deep Learning/SeussDream/dog\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = \"./dog\"\n",
    "snapshot_download(\n",
    "    \"diffusers/dog-example\",\n",
    "    local_dir=local_dir,\n",
    "    repo_type=\"dataset\",\n",
    "    ignore_patterns=\".gitattributes\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /sddata/dreambooth/daruma-v2-1/checkpoint-100/unet is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/configuration_utils.py:370\u001b[0m, in \u001b[0;36mConfigMixin.load_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     config_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    371\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    372\u001b[0m         filename\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_name,\n\u001b[1;32m    373\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    374\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    375\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    376\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    377\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    378\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    379\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    380\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    381\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    382\u001b[0m     )\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    112\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/gianyrox1/Library/Mobile Documents/com~apple~CloudDocs/GDD School/Stevens'24/Semester 7/CS 583 Deep Learning/SeussDream/SeussDream-testing.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Load the pipeline with the same arguments (model, revision) that were used for training\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m unet \u001b[39m=\u001b[39m UNet2DConditionModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# if you have trained with `--args.train_text_encoder` make sure to also load the text encoder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m text_encoder \u001b[39m=\u001b[39m CLIPTextModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39m/sddata/dreambooth/daruma-v2-1/checkpoint-100/text_encoder\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:711\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m user_agent \u001b[39m=\u001b[39m {\n\u001b[1;32m    705\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdiffusers\u001b[39m\u001b[39m\"\u001b[39m: __version__,\n\u001b[1;32m    706\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfile_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    707\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mframework\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m }\n\u001b[1;32m    710\u001b[0m \u001b[39m# load config\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m config, unused_kwargs, commit_hash \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload_config(\n\u001b[1;32m    712\u001b[0m     config_path,\n\u001b[1;32m    713\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    714\u001b[0m     return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m     return_commit_hash\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    716\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    717\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    718\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    719\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    720\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    721\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    722\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    723\u001b[0m     device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m    724\u001b[0m     max_memory\u001b[39m=\u001b[39;49mmax_memory,\n\u001b[1;32m    725\u001b[0m     offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m    726\u001b[0m     offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m    727\u001b[0m     user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    728\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m \u001b[39m# load model\u001b[39;00m\n\u001b[1;32m    732\u001b[0m model_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/configuration_utils.py:406\u001b[0m, in \u001b[0;36mConfigMixin.load_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    402\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    405\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in the cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m directory containing a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mconfig_name\u001b[39m}\u001b[39;00m\u001b[39m file.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m run the library in offline mode at\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/diffusers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m     )\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mconfig_name\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /sddata/dreambooth/daruma-v2-1/checkpoint-100/unet is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel\n",
    "import torch\n",
    "\n",
    "# Load the pipeline with the same arguments (model, revision) that were used for training\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\"/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet\")\n",
    "\n",
    "# if you have trained with `--args.train_text_encoder` make sure to also load the text encoder\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"/sddata/dreambooth/daruma-v2-1/checkpoint-100/text_encoder\")\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    model_id, unet=unet, text_encoder=text_encoder, dtype=torch.float16, use_safetensors=True\n",
    ")\n",
    "pipeline.to(\"cuda\")\n",
    "\n",
    "# Perform inference, or save, or push to the hub\n",
    "pipeline.save_pretrained(\"dreambooth-pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!#!/bin/bash\n",
    "export MODEL_NAME=\"duongna/stable-diffusion-v1-4-flax\"\n",
    "export INSTANCE_DIR=\"./dog\"\n",
    "export OUTPUT_DIR=\"/Users/gianyrox1/Library/Mobile Documents/com~apple~CloudDocs/GDD School/Stevens'24/Semester 7/CS 583 Deep Learning/SeussDream\"\n",
    "\n",
    "\n",
    "accelerate launch train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME  \\\n",
    "  --instance_data_dir=$INSTANCE_DIR \\\n",
    "  --output_dir=$OUTPUT_DIR \\\n",
    "  --instance_prompt=\"a photo of a dog\" \\\n",
    "  --resolution=500 \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --learning_rate=5e-6 \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --checkpointing_steps=20 \\\n",
    "  --max_train_steps=400 \\\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline, UNet2DConditionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /sddata/dreambooth/daruma-v2-1/checkpoint-100/unet is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/configuration_utils.py:370\u001b[0m, in \u001b[0;36mConfigMixin.load_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     config_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    371\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m    372\u001b[0m         filename\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mconfig_name,\n\u001b[1;32m    373\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    374\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    375\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    376\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    377\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    378\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    379\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    380\u001b[0m         subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    381\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    382\u001b[0m     )\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    112\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:158\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet'. Use `repo_type` argument if needed.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/gianyrox1/Library/Mobile Documents/com~apple~CloudDocs/GDD School/Stevens'24/Semester 7/CS 583 Deep Learning/SeussDream/SeussDream-testing.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Load the pipeline with the same arguments (model, revision) that were used for training\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVis/stable-diffusion-v1-4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m unet \u001b[39m=\u001b[39m UNet2DConditionModel\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39m/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# if you have trained with `--args.train_text_encoder` make sure to also load the text encoder\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gianyrox1/Library/Mobile%20Documents/com~apple~CloudDocs/GDD%20School/Stevens%2724/Semester%207/CS%20583%20Deep%20Learning/SeussDream/SeussDream-testing.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m text_encoder \u001b[39m=\u001b[39m CLIPTextModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39m/sddata/dreambooth/daruma-v2-1/checkpoint-100/text_encoder\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/models/modeling_utils.py:711\u001b[0m, in \u001b[0;36mModelMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m user_agent \u001b[39m=\u001b[39m {\n\u001b[1;32m    705\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdiffusers\u001b[39m\u001b[39m\"\u001b[39m: __version__,\n\u001b[1;32m    706\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mfile_type\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    707\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mframework\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpytorch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    708\u001b[0m }\n\u001b[1;32m    710\u001b[0m \u001b[39m# load config\u001b[39;00m\n\u001b[0;32m--> 711\u001b[0m config, unused_kwargs, commit_hash \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload_config(\n\u001b[1;32m    712\u001b[0m     config_path,\n\u001b[1;32m    713\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    714\u001b[0m     return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    715\u001b[0m     return_commit_hash\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    716\u001b[0m     force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    717\u001b[0m     resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    718\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    719\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    720\u001b[0m     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    721\u001b[0m     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    722\u001b[0m     subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[1;32m    723\u001b[0m     device_map\u001b[39m=\u001b[39;49mdevice_map,\n\u001b[1;32m    724\u001b[0m     max_memory\u001b[39m=\u001b[39;49mmax_memory,\n\u001b[1;32m    725\u001b[0m     offload_folder\u001b[39m=\u001b[39;49moffload_folder,\n\u001b[1;32m    726\u001b[0m     offload_state_dict\u001b[39m=\u001b[39;49moffload_state_dict,\n\u001b[1;32m    727\u001b[0m     user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    728\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    729\u001b[0m )\n\u001b[1;32m    731\u001b[0m \u001b[39m# load model\u001b[39;00m\n\u001b[1;32m    732\u001b[0m model_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/diffusers/configuration_utils.py:406\u001b[0m, in \u001b[0;36mConfigMixin.load_config\u001b[0;34m(cls, pretrained_model_name_or_path, return_unused_kwargs, return_commit_hash, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    402\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    405\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in the cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m directory containing a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mconfig_name\u001b[39m}\u001b[39;00m\u001b[39m file.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m run the library in offline mode at\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/diffusers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m     )\n\u001b[1;32m    413\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mconfig_name\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /sddata/dreambooth/daruma-v2-1/checkpoint-100/unet is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/diffusers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel\n",
    "import torch\n",
    "\n",
    "# Load the pipeline with the same arguments (model, revision) that were used for training\n",
    "model_id = \"CompVis/stable-diffusion-v1-4\"\n",
    "\n",
    "unet = UNet2DConditionModel.from_pretrained(\"/sddata/dreambooth/daruma-v2-1/checkpoint-100/unet\")\n",
    "\n",
    "# if you have trained with `--args.train_text_encoder` make sure to also load the text encoder\n",
    "text_encoder = CLIPTextModel.from_pretrained(\"/sddata/dreambooth/daruma-v2-1/checkpoint-100/text_encoder\")\n",
    "\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    model_id, unet=unet, text_encoder=text_encoder, dtype=torch.float16, use_safetensors=True\n",
    ")\n",
    "pipeline.to(\"cuda\")\n",
    "\n",
    "# Perform inference, or save, or push to the hub\n",
    "pipeline.save_pretrained(\"dreambooth-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
